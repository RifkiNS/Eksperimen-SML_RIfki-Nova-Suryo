# -*- coding: utf-8 -*-
"""Preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sxv-yFWGSKcqdi7wEHMK0rnRNsYWpjpZ

# **1. Perkenalan Dataset**

Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:

1. **Sumber Dataset**:  
   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.

# **2. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan melakukan preprocessing.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

from sklearn.preprocessing import StandardScaler

"""# **3. Memuat Dataset**

Pada tahap ini adalah memuat dataset ke dalam notebook. Menggunakan pustaka pandas untuk membacanya karena dataset berbentuk CSV.
"""

df= pd.read_csv('train.csv')
df.head()

"""# **4. Exploratory Data Analysis (EDA)**

Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.

Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan.

### 4.1 Quality check ###
Tahap ini dilakukan untuk memerikas tipe data pada dataset sudah seusai atau belum, mengecek apakah terdapat missing value atau tidak dan melihat ringkasan ststistik dataset.
"""

df.info()

df.describe()

df.isnull().sum()

"""### 4.2 Visualisasi dataset ##3
Pada tahap ini melakukan visualisasi untuk mengenal lebih jauh mengenai dataset. Tahap ini berisikan visualisasi perebaran dataset, visualisasi korelasi antar fitur pada dataset dan melihat outlier pada dataset.
"""

for feature in df.columns:
    plt.figure(figsize=(10,6))
    sns.boxplot(df[feature])
    plt.title(f'Box Plot of {feature}')
    plt.show()

num_vars = df.shape[1]

n_cols = 4
n_rows = -(-num_vars // n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows*4))

axes = axes.flatten()

for i, column in enumerate(df.columns):
    df[column].hist(ax=axes[i], bins=20, edgecolor='black')
    axes[i].set_title(column)
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')

for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

target_corr = df.corr()['FloodProbability']

target_corr_sorted = target_corr.abs().sort_values(ascending=False)

plt.figure(figsize=(10, 6))
target_corr_sorted.plot(kind='bar')
plt.title('Correlation with SalePrice')
plt.xlabel('Variables')
plt.ylabel('Correlation Coef')
plt.show()

"""# **5. Data Preprocessing**

Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.
Berikut adalah tahapan-tahapan yang bisa dilakukan pada submission ini:
1. Deteksi dan Penanganan Outlier
2. Standarisasi Fitur

### Menangani Outlier ###
"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

condition = ~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)
df = df.loc[condition, df.columns]

"""### Standarosasi ###"""

numeric_features = df.select_dtypes(include=['number']).columns
numeric_features

scaler = StandardScaler()
df[numeric_features] = scaler.fit_transform(df[numeric_features])

"""## Merubah dataset yang sudah dilakukan preprocessing kedalam CSV ###"""

df.to_csv('flood_preprocessing.csv', index=False)